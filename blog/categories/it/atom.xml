<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: it | Marcin bloguje]]></title>
  <link href="http://zygm0nt.github.com/blog/categories/it/atom.xml" rel="self"/>
  <link href="http://zygm0nt.github.com/"/>
  <updated>2016-10-09T23:10:09+02:00</updated>
  <id>http://zygm0nt.github.com/</id>
  <author>
    <name><![CDATA[Marcin Cylke]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Distributed scans with HBase]]></title>
    <link href="http://zygm0nt.github.com/blog/2013/12/10/distributed-scans-with-hbase/"/>
    <updated>2013-12-10T21:26:00+01:00</updated>
    <id>http://zygm0nt.github.com/blog/2013/12/10/distributed-scans-with-hbase</id>
    <content type="html"><![CDATA[<p>HBase is by design a columnar store, that is optimized for random reads.
You just ask for a row using rowId as an identifier and you get your
data instantaneously.</p>

<p>Performing a scan on part or whole table is a completely different thing.
First of all, it is sequential. Meaning it is rather slow, because it
doesn't use all the RegionServers at the same time. It is implemented
that way to realize the contract of Scan command - which has to return
results sorted by key.</p>

<p>So, how to do this efficiently?</p>

<!-- more -->


<p>The usual way of getting data from HBase is with the help of its API,
mainly Scan objects. To accomplish the task I'll use just them. I'll
specify startRow and stopRow, so that each Scan request will be looking
through only part of the key space.</p>

<p>It is crucial to note, that this whole solution works because of key
sorting properties in HBase. So, HBase scans a table according to ascending key
values. Since keys are of String type, key with value "1" is smaller
than "2", because they are sorted lexicographicly. So, also key with value "12345" is smaller than "2". I've
leveraged this property so that I've partitioned my whole key space according to
the first character of the key. In my case keys contain only digits. So I
have 10 ranges:</p>

<ul>
<li>null-1</li>
<li>1-2</li>
<li>2-3</li>
<li>3-4</li>
<li>4-5</li>
<li>5-6</li>
<li>6-7</li>
<li>7-8</li>
<li>8-9</li>
<li>9-null</li>
</ul>


<p>The speedup comes from the fact, that each range resides in its own
partition. That's right, I've presplit the table to have 10 partitions.
This corresponds rather nicely with my cluster's setup, because I have
more than 10 RegionServers. So every partition should be on different
RegionServer. It will allow the code to do the requested scan operations
in parallel - giving me this exact performance boost.</p>

<p>How I've created the input table:</p>

<p><code></p>

<p>$ create 'tariff_changes', { NAME => 'cf', SPLITS_FILE => 'splits.txt', VERSIONS => 50, MAX_FILESIZE => 1073741824 }</p>

<p>$ alter 'tariff_changes', { NAME => 'cf', SPLITS_FILE => 'splits.txt', VERSIONS => 50, MAX_FILESIZE => 1073741824 }</p>

<p></code></p>

<p>Split file is just something along this lines:</p>

<p><code>
1
2
3
4
5
6
7
8
9
0
</code></p>

<p>This tells HBase what are the rowKeys starting and ending each of the
partitions.</p>

<p>Ok, so after this rather lengthy introduction, what the actual code
does? It just spins of a few threads - one for each partition - and runs
a Scan request tailored to that partitions key space. This way, I got a
10x speedup for this particular scan. The execution time went down from
30 minutes to 3 for my use case.</p>

<p>I've created an example implementation of this idea. You can find it on
GitHub:
<a href="https://github.com/zygm0nt/hbase-distributed-search">https://github.com/zygm0nt/hbase-distributed-search</a>.</p>

<p>Any ideas on how to speed things up even more with HBase?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple HBase ORM]]></title>
    <link href="http://zygm0nt.github.com/blog/2013/12/08/simple-hbase-orm/"/>
    <updated>2013-12-08T21:08:00+01:00</updated>
    <id>http://zygm0nt.github.com/blog/2013/12/08/simple-hbase-orm</id>
    <content type="html"><![CDATA[<p>When dealing with data stored in HBase, you are quick to come to a
conclusion, that it is extremaly inconvenient to reach to it
via HBase native API. It is very verbose and you always need to convert
between bytes and simple types - a pain.</p>

<p>While I was working on a project of mine, I thought, why not to easy
those pains and fetch real objects from HBase.</p>

<p>And that's how this simplistic, hackish ORM came to life. It is no match
for projects like <a href="https://github.com/impetus-opensource/Kundera">Kundera</a>
(a JPA compliant solution), or <a href="https://code.google.com/p/n-orm/">n-orm</a>. Nevertheless, it just suits my needs :)</p>

<!-- more -->


<p>Project sources are hosted on GitHub: <a href="https://github.com/zygm0nt/hbase-annotations">https://github.com/zygm0nt/hbase-annotations</a></p>

<p>To make use of this, you need to have an entity class with annotations:</p>

<ul>
<li>@Column - with argument specifying column family and column name, ie.
@Column("cf:column-name")</li>
<li>@Id - will store row key in this property,</li>
<li>and optionaly @Value - for Spring Expression Language, in case you
need to perform some extraction on the value.</li>
</ul>


<p><em>Annotations should be on setter methods.</em></p>

<p>Now you have your model annotated and ready to be fetched from HBase.</p>

<p>The actual work is done with a service class, that should extend class
<a href="https://github.com/zygm0nt/hbase-annotations/blob/master/src/main/java/pl/touk/hadoop/hbase/BaseHadoopInteraction.java">BaseHadoopInteraction</a> just as class
<a href="https://github.com/zygm0nt/hbase-annotations/blob/master/src/test/java/pl/touk/hadoop/hbase/SampleHBaseClient.java">SimpleHBaseClient</a> does.</p>

<p>Then it is possible to just call:</p>

<script src="https://gist.github.com/zygm0nt/7863407.js"></script>


<p>Note that there are more methods you can use on BaseHadoopInteraction.
You can also do:</p>

<ul>
<li>scan</li>
<li>scan with key ranges</li>
<li>delete</li>
</ul>


<p>What you won't get from this simple ORM is:</p>

<ul>
<li>automatic object updating,</li>
<li>nested objects,</li>
<li>saving to HBase - 'cause I didn't have a need for that,</li>
</ul>


<p>Hope you'll find this piece of code useful. If you see room for
improvements while staying in project's scope - please drop me a
message.</p>

<p>And if you are searching for a full-fledged ORM solution for interacting with HBase, just head
straight to Kundera project website :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recently at storm-users]]></title>
    <link href="http://zygm0nt.github.com/blog/2013/08/12/recently-at-storm-users/"/>
    <updated>2013-08-12T22:26:00+02:00</updated>
    <id>http://zygm0nt.github.com/blog/2013/08/12/recently-at-storm-users</id>
    <content type="html"><![CDATA[<p>I've been reading through storm-users Google Group recently. This
resolution was heavily inspired by Adam Kawa's post <a href="http://hakunamapdata.com/football-zero-apache-pig-hero-the-essence-from-hundreds-of-posts-from-apache-pig-user-mailing-list/">"Football zero, Apache Pig hero"</a>. Since I've encountered a lot of insightful and very interesting information I've decided to describe some of those in this post.</p>

<!-- more -->


<ul>
<li><p>nimbus will work in HA mode - There's a pull request open for it already... but some
recent work (distributing topology files via Bittorrent) will greatly
simplify the implementation. Once the Bittorrent work is done we'll look
at reworking the HA pull request. (<a href="https://github.com/nathanmarz/storm/pull/629">storm’s pull request</a>)</p></li>
<li><p>pig on storm - Pig on Trident would be a cool and welcome project. Join
and groupBy have very clear semantics there, as those concepts exist
directly in Trident. The extensions needed to Pig are the concept of
incremental, persistent state across batches (mirroring those concepts
in Trident). You can read a complete <a href="https://cwiki.apache.org/confluence/display/PIG/Pig+on+Storm+Proposal">proposal</a>.</p></li>
<li><p>implementing topologies in pure python with <a href="https://github.com/AirSage/Petrel">petrel</a> looks like this:</p></li>
</ul>


<blockquote><pre><code>class Bolt(storm.BasicBolt):
    def initialize(self, conf, context):
       ''' This method executed only once '''
        storm.log('initializing bolt')

    def process(self, tup):
       ''' This method executed every time a new tuple arrived '''       
       msg = tup.values[0]
       storm.log('Got tuple %s' %msg)

if __name__ == "__main__":
    Bolt().run()
</code></pre></blockquote>

<ul>
<li><p>Fliptop is happy with storm - see their presentation <a href="http://www.slideshare.net/robbiecheng/lesson-learned-of-twitter-storm">here</a></p></li>
<li><p>topology metrics in 0.9.0: The new metrics feature allows you to collect
arbitrarily custom metrics over fixed windows. Those metrics are
exported to a metrics stream that you can consume by implementing
<a href="https://github.com/nathanmarz/storm/blob/master/storm-core/src/jvm/backtype/storm/metric/api/IMetricsConsumer.java">IMetricsConsumer</a> and configure with <a href="https://github.com/nathanmarz/storm/blob/master/storm-core/src/jvm/backtype/storm/Config.java#L473">Config.java#L473</a>.
Use <strong>TopologyContext#registerMetric</strong> to register new metrics.</p></li>
<li><p>storm vs flume - some users' point of view: I use Storm and Flume and find that they are better at
different things - it really depends on your use case as to which one is
better suited. First and foremost, they were originally designed to do
different things: Flume is a reliable service for collecting,
aggregating, and moving large amounts of data from source to destination
(e.g. log data from many web servers to HDFS). Storm is more for
real-time computation (e.g. streaming analytics) where you analyse data
in flight and don't necessarily land it anywhere. Having said that,
Storm is also fault-tolerant and can write to external data stores (e.g.
HBase) and you can do real-time computation in Flume (using
interceptors)</p></li>
</ul>


<p>That's all for this day - however, I'll keep on reading through storm-users, so watch this space for more info on storm development.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[After WHUG meeting]]></title>
    <link href="http://zygm0nt.github.com/blog/2012/11/30/after-whug/"/>
    <updated>2012-11-30T22:20:00+01:00</updated>
    <id>http://zygm0nt.github.com/blog/2012/11/30/after-whug</id>
    <content type="html"><![CDATA[<p>Here are the slides from the talk a gave yesterday. If you have any
questions, please ask.</p>

<script async class="speakerdeck-embed"
data-id="cc18d5601d60013059a31231381554d7" data-ratio="1.33333333333333"
src="http://zygm0nt.github.com//speakerdeck.com/assets/embed.js"></script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WHUG 8. Beyond Hadoop - checking other options]]></title>
    <link href="http://zygm0nt.github.com/blog/2012/11/26/whug-8-beyond-hadoop/"/>
    <updated>2012-11-26T09:11:00+01:00</updated>
    <id>http://zygm0nt.github.com/blog/2012/11/26/whug-8-beyond-hadoop</id>
    <content type="html"><![CDATA[<p>W najbliższy czwartek - czyli 29.11.2012 - poprowadzę prezentację w
ramach Warsaw Hadoop User Group. Swoją obecność można odklinąć tu
http://www.meetup.com/warsaw-hug/</p>

<p>A o czym będę mówił? Przeklejka ze strony WHUG:</p>

<blockquote><p>Marcin skupi się na współpracy ekosystemu Hadoopa z innymi narzędziami.
Pokaże jak prosto i wygodnie przetwarzać grafy i jak stosować podejście
Big Data, w czasie rzeczywistym. Poruszy również temat łatwiejszego
tworzenia algorytmów Map-Reduce</p>

<p>Będzie to nieco mniej technicza (ale wciąż praktyczna) wycieczka po
obrzeżach tematyki, która jest zwykle poruszana w połączeniu z
Hadoop-em.</p>

<p>Prezentacja będzie dotyczyć narzędzi takich jak Cascading, Storm, Titan.</p></blockquote>

<p>Zapraszam!</p>
]]></content>
  </entry>
  
</feed>
