<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hbase on Just a blog</title>
    <link>http://marcin.cylke.com.pl/categories/hbase/</link>
    <description>Recent content in Hbase on Just a blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2013 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://marcin.cylke.com.pl/categories/hbase/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Distributed scans with HBase</title>
      <link>http://marcin.cylke.com.pl/2013/12/10/distributed-scans-with-hbase/</link>
      <pubDate>Tue, 10 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>http://marcin.cylke.com.pl/2013/12/10/distributed-scans-with-hbase/</guid>
      <description>&lt;p&gt;HBase is by design a columnar store, that is optimized for random reads.
You just ask for a row using rowId as an identifier and you get your
data instantaneously.&lt;/p&gt;

&lt;p&gt;Performing a scan on part or whole table is a completely different thing.
First of all, it is sequential. Meaning it is rather slow, because it
doesn&amp;rsquo;t use all the RegionServers at the same time. It is implemented
that way to realize the contract of Scan command - which has to return
results sorted by key.&lt;/p&gt;

&lt;p&gt;So, how to do this efficiently?&lt;/p&gt;

&lt;p&gt;The usual way of getting data from HBase is with the help of its API,
mainly Scan objects. To accomplish the task I&amp;rsquo;ll use just them. I&amp;rsquo;ll
specify startRow and stopRow, so that each Scan request will be looking
through only part of the key space.&lt;/p&gt;

&lt;p&gt;It is crucial to note, that this whole solution works because of key
sorting properties in HBase. So, HBase scans a table according to ascending key
values. Since keys are of String type, key with value &amp;ldquo;1&amp;rdquo; is smaller
than &amp;ldquo;2&amp;rdquo;, because they are sorted lexicographicly. So, also key with value &amp;ldquo;12345&amp;rdquo; is smaller than &amp;ldquo;2&amp;rdquo;. I&amp;rsquo;ve
leveraged this property so that I&amp;rsquo;ve partitioned my whole key space according to
the first character of the key. In my case keys contain only digits. So I
have 10 ranges:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;null-1&lt;/li&gt;
&lt;li&gt;1-2&lt;/li&gt;
&lt;li&gt;2-3&lt;/li&gt;
&lt;li&gt;3-4&lt;/li&gt;
&lt;li&gt;4-5&lt;/li&gt;
&lt;li&gt;5-6&lt;/li&gt;
&lt;li&gt;6-7&lt;/li&gt;
&lt;li&gt;7-8&lt;/li&gt;
&lt;li&gt;8-9&lt;/li&gt;
&lt;li&gt;9-null&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The speedup comes from the fact, that each range resides in its own
partition. That&amp;rsquo;s right, I&amp;rsquo;ve presplit the table to have 10 partitions.
This corresponds rather nicely with my cluster&amp;rsquo;s setup, because I have
more than 10 RegionServers. So every partition should be on different
RegionServer. It will allow the code to do the requested scan operations
in parallel - giving me this exact performance boost.&lt;/p&gt;

&lt;p&gt;How I&amp;rsquo;ve created the input table:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;/p&gt;

&lt;p&gt;$ create &amp;lsquo;tariff_changes&amp;rsquo;, { NAME =&amp;gt; &amp;lsquo;cf&amp;rsquo;, SPLITS_FILE =&amp;gt; &amp;lsquo;splits.txt&amp;rsquo;, VERSIONS =&amp;gt; 50, MAX_FILESIZE =&amp;gt; 1073741824 }&lt;/p&gt;

&lt;p&gt;$ alter &amp;lsquo;tariff_changes&amp;rsquo;, { NAME =&amp;gt; &amp;lsquo;cf&amp;rsquo;, SPLITS_FILE =&amp;gt; &amp;lsquo;splits.txt&amp;rsquo;, VERSIONS =&amp;gt; 50, MAX_FILESIZE =&amp;gt; 1073741824 }&lt;/p&gt;

&lt;p&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Split file is just something along this lines:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
1
2
3
4
5
6
7
8
9
0
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This tells HBase what are the rowKeys starting and ending each of the
partitions.&lt;/p&gt;

&lt;p&gt;Ok, so after this rather lengthy introduction, what the actual code
does? It just spins of a few threads - one for each partition - and runs
a Scan request tailored to that partitions key space. This way, I got a
10x speedup for this particular scan. The execution time went down from
30 minutes to 3 for my use case.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve created an example implementation of this idea. You can find it on
GitHub:
&lt;a href=&#34;https://github.com/zygm0nt/hbase-distributed-search&#34;&gt;https://github.com/zygm0nt/hbase-distributed-search&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Any ideas on how to speed things up even more with HBase?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simple HBase ORM</title>
      <link>http://marcin.cylke.com.pl/2013/12/08/simple-hbase-orm/</link>
      <pubDate>Sun, 08 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>http://marcin.cylke.com.pl/2013/12/08/simple-hbase-orm/</guid>
      <description>&lt;p&gt;When dealing with data stored in HBase, you are quick to come to a
conclusion, that it is extremaly inconvenient to reach to it
via HBase native API. It is very verbose and you always need to convert
between bytes and simple types - a pain.&lt;/p&gt;

&lt;p&gt;While I was working on a project of mine, I thought, why not to easy
those pains and fetch real objects from HBase.&lt;/p&gt;

&lt;p&gt;And that&amp;rsquo;s how this simplistic, hackish ORM came to life. It is no match
for projects like &lt;a href=&#34;https://github.com/impetus-opensource/Kundera&#34;&gt;Kundera&lt;/a&gt;
(a JPA compliant solution), or &lt;a href=&#34;https://code.google.com/p/n-orm/&#34;&gt;n-orm&lt;/a&gt;. Nevertheless, it just suits my needs :)&lt;/p&gt;

&lt;p&gt;Project sources are hosted on GitHub: &lt;a href=&#34;https://github.com/zygm0nt/hbase-annotations&#34;&gt;https://github.com/zygm0nt/hbase-annotations&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To make use of this, you need to have an entity class with annotations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;@Column - with argument specifying column family and column name, ie.
@Column(&amp;ldquo;cf:column-name&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;@Id - will store row key in this property,&lt;/li&gt;
&lt;li&gt;and optionaly @Value - for Spring Expression Language, in case you
need to perform some extraction on the value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Annotations should be on setter methods.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now you have your model annotated and ready to be fetched from HBase.&lt;/p&gt;

&lt;p&gt;The actual work is done with a service class, that should extend class
&lt;a href=&#34;https://github.com/zygm0nt/hbase-annotations/blob/master/src/main/java/pl/touk/hadoop/hbase/BaseHadoopInteraction.java&#34;&gt;BaseHadoopInteraction&lt;/a&gt; just as class
&lt;a href=&#34;https://github.com/zygm0nt/hbase-annotations/blob/master/src/test/java/pl/touk/hadoop/hbase/SampleHBaseClient.java&#34;&gt;SimpleHBaseClient&lt;/a&gt; does.&lt;/p&gt;

&lt;p&gt;Then it is possible to just call:&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/zygm0nt/7863407.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Note that there are more methods you can use on BaseHadoopInteraction.
You can also do:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;scan&lt;/li&gt;
&lt;li&gt;scan with key ranges&lt;/li&gt;
&lt;li&gt;delete&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What you won&amp;rsquo;t get from this simple ORM is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;automatic object updating,&lt;/li&gt;
&lt;li&gt;nested objects,&lt;/li&gt;
&lt;li&gt;saving to HBase - &amp;lsquo;cause I didn&amp;rsquo;t have a need for that,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hope you&amp;rsquo;ll find this piece of code useful. If you see room for
improvements while staying in project&amp;rsquo;s scope - please drop me a
message.&lt;/p&gt;

&lt;p&gt;And if you are searching for a full-fledged ORM solution for interacting with HBase, just head
straight to Kundera project website :)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>